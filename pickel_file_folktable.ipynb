{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# !pip install folktables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#info about Data\n",
    "# https://arxiv.org/pdf/2108.04884.pdf\n",
    "\n",
    "#ACSDataSource ,ACSEmployment, ACSPublicCoverage, ACSIncome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> (using ACSEmployment) from the paper: predict whether an individual is employed, after filtering the ACS PUMS data\n",
    "sample to only include individuals between the ages of 16 and 90  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn import preprocessing\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from folktables import ACSDataSource, ACSEmployment,ACSIncome\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detail about the state: load_acs.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from folktables import ACSDataSource, ACSEmployment,ACSIncome\n",
    "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')\n",
    "acs_data = data_source.get_data(states=[\"AL\"], download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_np, label_np, group_np = ACSEmployment.df_to_numpy(acs_data)\n",
    "features, label, group = ACSEmployment.df_to_pandas(acs_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGEP</th>\n",
       "      <th>SCHL</th>\n",
       "      <th>MAR</th>\n",
       "      <th>RELP</th>\n",
       "      <th>DIS</th>\n",
       "      <th>ESP</th>\n",
       "      <th>CIT</th>\n",
       "      <th>MIG</th>\n",
       "      <th>MIL</th>\n",
       "      <th>ANC</th>\n",
       "      <th>NATIVITY</th>\n",
       "      <th>DEAR</th>\n",
       "      <th>DEYE</th>\n",
       "      <th>DREM</th>\n",
       "      <th>SEX</th>\n",
       "      <th>RAC1P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47772</th>\n",
       "      <td>18.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47773</th>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47774</th>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47775</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47776</th>\n",
       "      <td>62.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47777 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AGEP  SCHL  MAR  RELP  DIS  ESP  CIT  MIG  MIL  ANC  NATIVITY  DEAR  \\\n",
       "0      19.0  18.0  5.0  17.0  2.0  0.0  1.0  3.0  4.0  1.0       1.0   2.0   \n",
       "1      18.0  18.0  5.0  17.0  2.0  0.0  1.0  3.0  4.0  1.0       1.0   2.0   \n",
       "2      53.0  17.0  5.0  16.0  1.0  0.0  1.0  1.0  4.0  2.0       1.0   2.0   \n",
       "3      28.0  19.0  5.0  16.0  2.0  0.0  1.0  1.0  2.0  1.0       1.0   2.0   \n",
       "4      25.0  12.0  5.0  16.0  1.0  0.0  1.0  3.0  4.0  1.0       1.0   2.0   \n",
       "...     ...   ...  ...   ...  ...  ...  ...  ...  ...  ...       ...   ...   \n",
       "47772  18.0  16.0  5.0   2.0  2.0  0.0  1.0  1.0  4.0  1.0       1.0   2.0   \n",
       "47773  15.0  11.0  5.0   2.0  2.0  7.0  1.0  1.0  0.0  1.0       1.0   2.0   \n",
       "47774  10.0   6.0  5.0   2.0  2.0  7.0  1.0  1.0  0.0  1.0       1.0   2.0   \n",
       "47775   4.0   1.0  5.0   2.0  2.0  7.0  1.0  1.0  0.0  1.0       1.0   2.0   \n",
       "47776  62.0  16.0  3.0   0.0  1.0  0.0  1.0  1.0  4.0  1.0       1.0   2.0   \n",
       "\n",
       "       DEYE  DREM  SEX  RAC1P  \n",
       "0       2.0   2.0  2.0    1.0  \n",
       "1       2.0   2.0  2.0    2.0  \n",
       "2       2.0   1.0  1.0    1.0  \n",
       "3       2.0   2.0  1.0    1.0  \n",
       "4       2.0   1.0  2.0    1.0  \n",
       "...     ...   ...  ...    ...  \n",
       "47772   2.0   2.0  2.0    1.0  \n",
       "47773   2.0   2.0  1.0    1.0  \n",
       "47774   2.0   2.0  1.0    1.0  \n",
       "47775   2.0   0.0  1.0    1.0  \n",
       "47776   2.0   2.0  1.0    1.0  \n",
       "\n",
       "[47777 rows x 16 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ESR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47772</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47773</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47774</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47775</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47776</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47777 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ESR\n",
       "0      False\n",
       "1      False\n",
       "2      False\n",
       "3      False\n",
       "4      False\n",
       "...      ...\n",
       "47772   True\n",
       "47773  False\n",
       "47774  False\n",
       "47775  False\n",
       "47776  False\n",
       "\n",
       "[47777 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGEP</th>\n",
       "      <th>SCHL</th>\n",
       "      <th>MAR</th>\n",
       "      <th>RELP</th>\n",
       "      <th>DIS</th>\n",
       "      <th>ESP</th>\n",
       "      <th>CIT</th>\n",
       "      <th>MIG</th>\n",
       "      <th>MIL</th>\n",
       "      <th>ANC</th>\n",
       "      <th>NATIVITY</th>\n",
       "      <th>DEAR</th>\n",
       "      <th>DEYE</th>\n",
       "      <th>DREM</th>\n",
       "      <th>SEX</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>ESR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGEP  SCHL  MAR  RELP  DIS  ESP  CIT  MIG  MIL  ANC  NATIVITY  DEAR  DEYE  \\\n",
       "0  19.0  18.0  5.0  17.0  2.0  0.0  1.0  3.0  4.0  1.0       1.0   2.0   2.0   \n",
       "1  18.0  18.0  5.0  17.0  2.0  0.0  1.0  3.0  4.0  1.0       1.0   2.0   2.0   \n",
       "2  53.0  17.0  5.0  16.0  1.0  0.0  1.0  1.0  4.0  2.0       1.0   2.0   2.0   \n",
       "3  28.0  19.0  5.0  16.0  2.0  0.0  1.0  1.0  2.0  1.0       1.0   2.0   2.0   \n",
       "4  25.0  12.0  5.0  16.0  1.0  0.0  1.0  3.0  4.0  1.0       1.0   2.0   2.0   \n",
       "\n",
       "   DREM  SEX  RAC1P    ESR  \n",
       "0   2.0  2.0    1.0  False  \n",
       "1   2.0  2.0    2.0  False  \n",
       "2   1.0  1.0    1.0  False  \n",
       "3   2.0  1.0    1.0  False  \n",
       "4   1.0  2.0    1.0  False  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df=pd.concat([features, label], axis=1)\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47777"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RAC1P\n",
       "1        35551\n",
       "2        10115\n",
       "9          835\n",
       "6          556\n",
       "8          491\n",
       "3          182\n",
       "5           33\n",
       "7           13\n",
       "4            1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    35551\n",
       "2.0    10115\n",
       "9.0      835\n",
       "6.0      556\n",
       "8.0      491\n",
       "3.0      182\n",
       "5.0       33\n",
       "7.0       13\n",
       "4.0        1\n",
       "Name: RAC1P, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df[\"RAC1P\"].value_counts()\n",
    "\n",
    "# 1: White alone – 2: Black or African American alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 8., 9., 6., 3., 5., 7., 4.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(merged_df[\"RAC1P\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(filtered_df):  45666 \n",
      "\n",
      "False    26881\n",
      "True     18785\n",
      "Name: ESR, dtype: int64 \n",
      "\n",
      "2.0    23737\n",
      "1.0    21929\n",
      "Name: SEX, dtype: int64 \n",
      "\n",
      "1.0    35551\n",
      "2.0    10115\n",
      "Name: RAC1P, dtype: int64 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEX</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>ESR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEX  RAC1P    ESR\n",
       "0  2.0    1.0  False\n",
       "1  2.0    2.0  False\n",
       "2  1.0    1.0  False\n",
       "3  1.0    1.0  False\n",
       "4  2.0    1.0  False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  for Black and white people\n",
    "filtered_df= merged_df[[\"SEX\",\"RAC1P\",\"ESR\"]][merged_df['RAC1P'].isin([1,2])]\n",
    "print(\"len(filtered_df): \", len(filtered_df),\"\\n\")\n",
    "print(filtered_df[\"ESR\"].value_counts(),\"\\n\")\n",
    "print(filtered_df[\"SEX\"].value_counts(),\"\\n\")\n",
    "print(filtered_df[\"RAC1P\"].value_counts(),\"\\n\")\n",
    "filtered_df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SEX  RAC1P\n",
       "1.0  1.0      17309\n",
       "     2.0       4620\n",
       "2.0  1.0      18242\n",
       "     2.0       5495\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1- Male 2- Female\n",
    "# 1- White 2-Black\n",
    "\n",
    "counts_frq = filtered_df.groupby(['SEX', 'RAC1P']).size()\n",
    "counts_frq"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "G1: train set: White men+black men+Black women—- validation set: black men\n",
    "\n",
    "G2: train: White women+black women+black men—- validation set: black women\n",
    "\n",
    "G3: train: black men+white men+white women+validation set: white men\n",
    "\n",
    "G4: train: white women+white men+black women, validation set: white women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGEP</th>\n",
       "      <th>SCHL</th>\n",
       "      <th>MAR</th>\n",
       "      <th>RELP</th>\n",
       "      <th>DIS</th>\n",
       "      <th>ESP</th>\n",
       "      <th>CIT</th>\n",
       "      <th>MIG</th>\n",
       "      <th>MIL</th>\n",
       "      <th>ANC</th>\n",
       "      <th>NATIVITY</th>\n",
       "      <th>DEAR</th>\n",
       "      <th>DEYE</th>\n",
       "      <th>DREM</th>\n",
       "      <th>SEX</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>ESR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47772</th>\n",
       "      <td>18.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47773</th>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47774</th>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47775</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47776</th>\n",
       "      <td>62.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47777 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AGEP  SCHL  MAR  RELP  DIS  ESP  CIT  MIG  MIL  ANC  NATIVITY  DEAR  \\\n",
       "0      19.0  18.0  5.0  17.0  2.0  0.0  1.0  3.0  4.0  1.0       1.0   2.0   \n",
       "1      18.0  18.0  5.0  17.0  2.0  0.0  1.0  3.0  4.0  1.0       1.0   2.0   \n",
       "2      53.0  17.0  5.0  16.0  1.0  0.0  1.0  1.0  4.0  2.0       1.0   2.0   \n",
       "3      28.0  19.0  5.0  16.0  2.0  0.0  1.0  1.0  2.0  1.0       1.0   2.0   \n",
       "4      25.0  12.0  5.0  16.0  1.0  0.0  1.0  3.0  4.0  1.0       1.0   2.0   \n",
       "...     ...   ...  ...   ...  ...  ...  ...  ...  ...  ...       ...   ...   \n",
       "47772  18.0  16.0  5.0   2.0  2.0  0.0  1.0  1.0  4.0  1.0       1.0   2.0   \n",
       "47773  15.0  11.0  5.0   2.0  2.0  7.0  1.0  1.0  0.0  1.0       1.0   2.0   \n",
       "47774  10.0   6.0  5.0   2.0  2.0  7.0  1.0  1.0  0.0  1.0       1.0   2.0   \n",
       "47775   4.0   1.0  5.0   2.0  2.0  7.0  1.0  1.0  0.0  1.0       1.0   2.0   \n",
       "47776  62.0  16.0  3.0   0.0  1.0  0.0  1.0  1.0  4.0  1.0       1.0   2.0   \n",
       "\n",
       "       DEYE  DREM  SEX  RAC1P    ESR  \n",
       "0       2.0   2.0  2.0    1.0  False  \n",
       "1       2.0   2.0  2.0    2.0  False  \n",
       "2       2.0   1.0  1.0    1.0  False  \n",
       "3       2.0   2.0  1.0    1.0  False  \n",
       "4       2.0   1.0  2.0    1.0  False  \n",
       "...     ...   ...  ...    ...    ...  \n",
       "47772   2.0   2.0  2.0    1.0   True  \n",
       "47773   2.0   2.0  1.0    1.0  False  \n",
       "47774   2.0   2.0  1.0    1.0  False  \n",
       "47775   2.0   0.0  1.0    1.0  False  \n",
       "47776   2.0   2.0  1.0    1.0  False  \n",
       "\n",
       "[47777 rows x 17 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # filter the dataframe for each combination\n",
    "\n",
    "#White Men\n",
    "WM = merged_df.loc[(merged_df['SEX'] == 1) & (merged_df['RAC1P'] == 1)]\n",
    "#Black Men\n",
    "BM = merged_df.loc[(merged_df['SEX'] == 1) & (merged_df['RAC1P'] == 2)]\n",
    "#white Women\n",
    "WW = merged_df.loc[(merged_df['SEX'] == 2) & (merged_df['RAC1P'] == 1)]\n",
    "#Black Women\n",
    "BW = merged_df.loc[(merged_df['SEX'] == 2) & (merged_df['RAC1P'] == 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGEP</th>\n",
       "      <th>SCHL</th>\n",
       "      <th>MAR</th>\n",
       "      <th>RELP</th>\n",
       "      <th>DIS</th>\n",
       "      <th>ESP</th>\n",
       "      <th>CIT</th>\n",
       "      <th>MIG</th>\n",
       "      <th>MIL</th>\n",
       "      <th>ANC</th>\n",
       "      <th>NATIVITY</th>\n",
       "      <th>DEAR</th>\n",
       "      <th>DEYE</th>\n",
       "      <th>DREM</th>\n",
       "      <th>SEX</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>ESR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>38.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>41.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>21.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47768</th>\n",
       "      <td>76.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47773</th>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47774</th>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47775</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47776</th>\n",
       "      <td>62.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17309 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AGEP  SCHL  MAR  RELP  DIS  ESP  CIT  MIG  MIL  ANC  NATIVITY  DEAR  \\\n",
       "2      53.0  17.0  5.0  16.0  1.0  0.0  1.0  1.0  4.0  2.0       1.0   2.0   \n",
       "3      28.0  19.0  5.0  16.0  2.0  0.0  1.0  1.0  2.0  1.0       1.0   2.0   \n",
       "7      38.0  12.0  5.0  16.0  1.0  0.0  1.0  1.0  4.0  4.0       1.0   1.0   \n",
       "8      41.0  16.0  5.0  17.0  2.0  0.0  1.0  1.0  4.0  4.0       1.0   2.0   \n",
       "14     21.0  19.0  5.0  17.0  2.0  0.0  1.0  1.0  1.0  2.0       1.0   2.0   \n",
       "...     ...   ...  ...   ...  ...  ...  ...  ...  ...  ...       ...   ...   \n",
       "47768  76.0  13.0  3.0   0.0  1.0  0.0  1.0  1.0  4.0  2.0       1.0   1.0   \n",
       "47773  15.0  11.0  5.0   2.0  2.0  7.0  1.0  1.0  0.0  1.0       1.0   2.0   \n",
       "47774  10.0   6.0  5.0   2.0  2.0  7.0  1.0  1.0  0.0  1.0       1.0   2.0   \n",
       "47775   4.0   1.0  5.0   2.0  2.0  7.0  1.0  1.0  0.0  1.0       1.0   2.0   \n",
       "47776  62.0  16.0  3.0   0.0  1.0  0.0  1.0  1.0  4.0  1.0       1.0   2.0   \n",
       "\n",
       "       DEYE  DREM  SEX  RAC1P    ESR  \n",
       "2       2.0   1.0  1.0    1.0  False  \n",
       "3       2.0   2.0  1.0    1.0  False  \n",
       "7       2.0   2.0  1.0    1.0  False  \n",
       "8       2.0   2.0  1.0    1.0   True  \n",
       "14      2.0   2.0  1.0    1.0  False  \n",
       "...     ...   ...  ...    ...    ...  \n",
       "47768   2.0   2.0  1.0    1.0  False  \n",
       "47773   2.0   2.0  1.0    1.0  False  \n",
       "47774   2.0   2.0  1.0    1.0  False  \n",
       "47775   2.0   0.0  1.0    1.0  False  \n",
       "47776   2.0   2.0  1.0    1.0  False  \n",
       "\n",
       "[17309 rows x 17 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Sex and Gen from 4 Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AGEP', 'SCHL', 'MAR', 'RELP', 'DIS', 'ESP', 'CIT', 'MIG', 'MIL', 'ANC',\n",
       "       'NATIVITY', 'DEAR', 'DEYE', 'DREM', 'SEX', 'RAC1P', 'ESR'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WM.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "WM_updated=WM[['AGEP', 'SCHL', 'MAR', 'RELP', 'DIS', 'ESP', 'CIT', 'MIG', 'MIL', 'ANC','NATIVITY', 'DEAR', 'DEYE', 'DREM', 'ESR']]\n",
    "BM_updated=BM[['AGEP', 'SCHL', 'MAR', 'RELP', 'DIS', 'ESP', 'CIT', 'MIG', 'MIL', 'ANC','NATIVITY', 'DEAR', 'DEYE', 'DREM', 'ESR']]\n",
    "WW_updated=WW[['AGEP', 'SCHL', 'MAR', 'RELP', 'DIS', 'ESP', 'CIT', 'MIG', 'MIL', 'ANC','NATIVITY', 'DEAR', 'DEYE', 'DREM', 'ESR']]\n",
    "BW_updated=BW[['AGEP', 'SCHL', 'MAR', 'RELP', 'DIS', 'ESP', 'CIT', 'MIG', 'MIL', 'ANC','NATIVITY', 'DEAR', 'DEYE', 'DREM', 'ESR']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group-1\n",
    "#Train set: White men+black men+Black women—- validation set: black men\n",
    "WM_BM_BW_train = pd.concat([WM_updated,BM_updated,BW_updated])\n",
    "BM_validation=BM_updated.copy()\n",
    "\n",
    "#Group-2\n",
    "#Train set: White women+black women+black men—- validation set: black women\n",
    "WW_BW_BM_train=pd.concat([WW_updated,BW_updated,BM_updated])\n",
    "BW_validation=BW_updated.copy()\n",
    "\n",
    "#Group-3\n",
    "#Train set: black men+white men+white women+validation set: white men\n",
    "BM_WM_WW_train=pd.concat([BM_updated,WM_updated,WW_updated])\n",
    "WM_validation=WM_updated.copy()\n",
    "\n",
    "#Group-4\n",
    "#Train set: white women+white men+black women, validation set: white women\n",
    "WW_WM_BW_train=pd.concat([WW_updated,WM_updated,BW_updated])\n",
    "WW_validation=WW_updated.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM 4620 RAC:  [2.] SEX:  [1.]\n",
      "BW 5495 RAC:  [2.] SEX:  [2.]\n",
      "WM 17309 RAC:  [1.] SEX:  [1.]\n",
      "WW 18242 RAC:  [1.] SEX:  [2.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"BM\" ,len(BM),\"RAC: \", pd.unique(BM['RAC1P']),\"SEX: \", pd.unique(BM['SEX']))\n",
    "print(\"BW\" ,len(BW),\"RAC: \", pd.unique(BW['RAC1P']),\"SEX: \", pd.unique(BW['SEX']))\n",
    "print(\"WM\" ,len(WM),\"RAC: \", pd.unique(WM['RAC1P']),\"SEX: \", pd.unique(WM['SEX']))\n",
    "print(\"WW\" ,len(WW),\"RAC: \", pd.unique(WW['RAC1P']),\"SEX: \", pd.unique(WW['SEX']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_use_train1= WM_BM_BW_train\n",
    "data_to_use_val1= BM_validation\n",
    "\n",
    "data_to_use_train2= WW_BW_BM_train\n",
    "data_to_use_val2= BW_validation\n",
    "\n",
    "\n",
    "data_to_use_train3= BM_WM_WW_train\n",
    "data_to_use_val3= WM_validation\n",
    "\n",
    "\n",
    "data_to_use_train4= WW_WM_BW_train\n",
    "data_to_use_val4= WW_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train1= data_to_use_train1[['AGEP', 'SCHL', 'MAR', 'RELP', 'DIS', 'ESP', 'CIT', 'MIG', 'MIL', 'ANC','NATIVITY', 'DEAR', 'DEYE', 'DREM']]\n",
    "y_train1= data_to_use_train1[['ESR']]\n",
    "\n",
    "\n",
    "X_train2= data_to_use_train2[['AGEP', 'SCHL', 'MAR', 'RELP', 'DIS', 'ESP', 'CIT', 'MIG', 'MIL', 'ANC','NATIVITY', 'DEAR', 'DEYE', 'DREM']]\n",
    "y_train2= data_to_use_train2[['ESR']]\n",
    "\n",
    "X_train3= data_to_use_train3[['AGEP', 'SCHL', 'MAR', 'RELP', 'DIS', 'ESP', 'CIT', 'MIG', 'MIL', 'ANC','NATIVITY', 'DEAR', 'DEYE', 'DREM']]\n",
    "y_train3= data_to_use_train3[['ESR']]\n",
    "\n",
    "X_train4= data_to_use_train4[['AGEP', 'SCHL', 'MAR', 'RELP', 'DIS', 'ESP', 'CIT', 'MIG', 'MIL', 'ANC','NATIVITY', 'DEAR', 'DEYE', 'DREM']]\n",
    "y_train4= data_to_use_train4[['ESR']]\n",
    "\n",
    "# X_train = torch.from_numpy(X_train.to_numpy()).float()\n",
    "# y_train = torch.squeeze(torch.from_numpy(y_train.to_numpy()).float())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid1 = data_to_use_val1[['AGEP', 'SCHL', 'MAR', 'RELP', 'DIS', 'ESP', 'CIT', 'MIG', 'MIL', 'ANC','NATIVITY', 'DEAR', 'DEYE', 'DREM']]\n",
    "y_valid1 = data_to_use_val1[['ESR']]\n",
    "\n",
    "X_valid2 = data_to_use_val2[['AGEP', 'SCHL', 'MAR', 'RELP', 'DIS', 'ESP', 'CIT', 'MIG', 'MIL', 'ANC','NATIVITY', 'DEAR', 'DEYE', 'DREM']]\n",
    "y_valid2 = data_to_use_val2[['ESR']]\n",
    "\n",
    "X_valid3 = data_to_use_val3[['AGEP', 'SCHL', 'MAR', 'RELP', 'DIS', 'ESP', 'CIT', 'MIG', 'MIL', 'ANC','NATIVITY', 'DEAR', 'DEYE', 'DREM']]\n",
    "y_valid3 = data_to_use_val3[['ESR']]\n",
    "\n",
    "X_valid4 = data_to_use_val4[['AGEP', 'SCHL', 'MAR', 'RELP', 'DIS', 'ESP', 'CIT', 'MIG', 'MIL', 'ANC','NATIVITY', 'DEAR', 'DEYE', 'DREM']]\n",
    "y_valid4 = data_to_use_val4[['ESR']]\n",
    "\n",
    "# X_valid = torch.from_numpy(X_valid.to_numpy()).float()\n",
    "# y_valid = torch.squeeze(torch.from_numpy(y_valid.to_numpy()).float())\n",
    "\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TYPE X:  <class 'numpy.ndarray'>  Type Y <class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "len(X_train),len(y_train), len(X_val),len(y_val):  27424 27424 4620 4620\n",
      "X_train.shape, y_train.shape  (27424, 14) (27424, 1) \n",
      "\n",
      "X_valid.shape, y_valid.shape  (4620, 14) (4620, 1) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.90734272, 0.29103446, 0.08559837, ..., 0.03423935, 0.03423935,\n",
       "        0.01711967],\n",
       "       [0.73531602, 0.49896444, 0.13130643, ..., 0.05252257, 0.05252257,\n",
       "        0.05252257],\n",
       "       [0.86858561, 0.27429019, 0.11428758, ..., 0.02285752, 0.04571503,\n",
       "        0.04571503],\n",
       "       ...,\n",
       "       [0.74337629, 0.62443609, 0.14867526, ..., 0.0594701 , 0.0594701 ,\n",
       "        0.0594701 ],\n",
       "       [0.98263061, 0.16983739, 0.01213124, ..., 0.02426248, 0.02426248,\n",
       "        0.02426248],\n",
       "       [0.95612824, 0.26838687, 0.05032254, ..., 0.03354836, 0.03354836,\n",
       "        0.03354836]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"TYPE X: \",type(X_train1),\" Type Y\", type(y_train1),\"\\n\")\n",
    "print(\"len(X_train),len(y_train), len(X_val),len(y_val): \",len(X_train1),len(y_train1), len(X_valid1),len(y_valid1))\n",
    "print(\"X_train.shape, y_train.shape \",X_train1.shape, y_train1.shape,\"\\n\")\n",
    "print(\"X_valid.shape, y_valid.shape \",X_valid1.shape, y_valid1.shape,\"\\n\")\n",
    "\n",
    "X_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ESR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47710</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47750</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47751</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47764</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47765</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27424 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ESR\n",
       "2      False\n",
       "3      False\n",
       "7      False\n",
       "8       True\n",
       "14     False\n",
       "...      ...\n",
       "47710   True\n",
       "47750  False\n",
       "47751   True\n",
       "47764  False\n",
       "47765  False\n",
       "\n",
       "[27424 rows x 1 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid1 = preprocessing.normalize(X_valid1)\n",
    "X_train1 = preprocessing.normalize(X_train1)\n",
    "\n",
    "X_valid2 = preprocessing.normalize(X_valid2)\n",
    "X_train2 = preprocessing.normalize(X_train2)\n",
    "\n",
    "X_valid3 = preprocessing.normalize(X_valid3)\n",
    "X_train3 = preprocessing.normalize(X_train3)\n",
    "\n",
    "X_valid4 = preprocessing.normalize(X_valid4)\n",
    "X_train4 = preprocessing.normalize(X_train4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Binary encoding of labels\n",
    "encoder.fit(y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    }
   ],
   "source": [
    "y_train1 = encoder.transform(y_train1)\n",
    "y_valid1 = encoder.transform(y_valid1)\n",
    "\n",
    "y_train2 = encoder.transform(y_train2)\n",
    "y_valid2 = encoder.transform(y_valid2)\n",
    "\n",
    "y_train3 = encoder.transform(y_train3)\n",
    "y_valid3 = encoder.transform(y_valid3)\n",
    "\n",
    "y_train4 = encoder.transform(y_train4)\n",
    "y_valid4 = encoder.transform(y_valid4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to 2D PyTorch tensors\n",
    "X_train1= torch.tensor(X_train1, dtype=torch.float32)\n",
    "X_valid1= torch.tensor(X_valid1, dtype=torch.float32)\n",
    "y_train1 = torch.tensor(y_train1, dtype=torch.float32).reshape(-1, 1)\n",
    "y_valid1 = torch.tensor(y_valid1, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "\n",
    "X_train2 = torch.tensor(X_train2, dtype=torch.float32)\n",
    "X_valid2 = torch.tensor(X_valid2, dtype=torch.float32)\n",
    "y_train2 = torch.tensor(y_train2, dtype=torch.float32).reshape(-1, 1)\n",
    "y_valid2 = torch.tensor(y_valid2, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "\n",
    "X_train3= torch.tensor(X_train3, dtype=torch.float32)\n",
    "X_valid3= torch.tensor(X_valid3, dtype=torch.float32)\n",
    "y_train3 = torch.tensor(y_train3, dtype=torch.float32).reshape(-1, 1)\n",
    "y_valid3 = torch.tensor(y_valid3, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "\n",
    "\n",
    "X_train4= torch.tensor(X_train4, dtype=torch.float32)\n",
    "X_valid4= torch.tensor(X_valid4, dtype=torch.float32)\n",
    "y_train4 = torch.tensor(y_train4, dtype=torch.float32).reshape(-1, 1)\n",
    "y_valid4 = torch.tensor(y_valid4, dtype=torch.float32).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.9073, 0.2910, 0.0856,  ..., 0.0342, 0.0342, 0.0171],\n",
       "         [0.7353, 0.4990, 0.1313,  ..., 0.0525, 0.0525, 0.0525],\n",
       "         [0.8686, 0.2743, 0.1143,  ..., 0.0229, 0.0457, 0.0457],\n",
       "         ...,\n",
       "         [0.7434, 0.6244, 0.1487,  ..., 0.0595, 0.0595, 0.0595],\n",
       "         [0.9826, 0.1698, 0.0121,  ..., 0.0243, 0.0243, 0.0243],\n",
       "         [0.9561, 0.2684, 0.0503,  ..., 0.0335, 0.0335, 0.0335]]),\n",
       " tensor([[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.]]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train1,y_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.]]),\n",
       " tensor([[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train1,y_valid1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([27424, 14]), torch.Size([27424, 1]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train1.shape, y_train1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data loader-torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Subset, random_split\n",
    "import torch.utils.data as data_utils\n",
    "import pickle\n",
    "# Passing to DataLoader\n",
    "\n",
    "train1 = data_utils.TensorDataset(X_train1, y_train1)\n",
    "valid1 = data_utils.TensorDataset(X_valid1, y_valid1)\n",
    "\n",
    "train2 = data_utils.TensorDataset(X_train2, y_train2)\n",
    "valid2 = data_utils.TensorDataset(X_valid2, y_valid2)\n",
    "\n",
    "train3 = data_utils.TensorDataset(X_train3, y_train3)\n",
    "valid3 = data_utils.TensorDataset(X_valid3, y_valid3)\n",
    "\n",
    "train4 = data_utils.TensorDataset(X_train4, y_train4)\n",
    "valid4 = data_utils.TensorDataset(X_valid4, y_valid4)\n",
    "\n",
    "trainloader1 = data_utils.DataLoader(train1, batch_size=10, shuffle=True)\n",
    "trainloader2 = data_utils.DataLoader(train2, batch_size=10, shuffle=True)\n",
    "trainloader3 = data_utils.DataLoader(train3, batch_size=10, shuffle=True)\n",
    "trainloader4 = data_utils.DataLoader(train4, batch_size=10, shuffle=True)\n",
    "\n",
    "valloader1 = data_utils.DataLoader(valid1, batch_size=10)\n",
    "valloader2 = data_utils.DataLoader(valid2, batch_size=10)\n",
    "valloader3 = data_utils.DataLoader(valid3, batch_size=10)\n",
    "valloader4 = data_utils.DataLoader(valid4, batch_size=10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_all_client=[trainloader1,trainloader2,trainloader3,trainloader4]\n",
    "val_data_all_client=[valloader1,valloader2,valloader3,valloader4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_1_client.pkl\", \"wb\") as f:\n",
    "    pickle.dump(train_data_all_client, f)\n",
    "    \n",
    "with open(\"valid_1_client.pkl\", \"wb\") as f:\n",
    "    pickle.dump(val_data_all_client, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data=[trainloader,trainloader,trainloader,trainloader]\n",
    "\n",
    "with open(\"chirag_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(all_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 14 : input shape\n",
    "        self.layer1 = nn.Linear(14, 512)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(p=0.5)\n",
    "        self.layer2 = nn.Linear(512, 256)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.layer3 = nn.Linear(256, 60)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.output = nn.Linear(60, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.layer1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.act2(self.layer2(x))\n",
    "        x = self.act3(self.layer3(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Loss: 0.6468, Validation Loss: 0.6594\n",
      "Epoch: 1, Training Loss: 0.6141, Validation Loss: 0.5916\n",
      "Epoch: 2, Training Loss: 0.5608, Validation Loss: 0.5433\n",
      "Epoch: 3, Training Loss: 0.5110, Validation Loss: 0.5282\n",
      "Epoch: 4, Training Loss: 0.5026, Validation Loss: 0.5274\n",
      "Epoch: 5, Training Loss: 0.5075, Validation Loss: 0.5250\n",
      "Epoch: 6, Training Loss: 0.4951, Validation Loss: 0.5303\n",
      "Epoch: 7, Training Loss: 0.4765, Validation Loss: 0.4805\n",
      "Epoch: 8, Training Loss: 0.5124, Validation Loss: 0.4598\n",
      "Epoch: 9, Training Loss: 0.5071, Validation Loss: 0.4601\n",
      "Accuracy (deep): 0.81, Validation Acc: 0.78\n",
      "Epoch: 0, Training Loss: 0.6165, Validation Loss: 0.6455\n",
      "Epoch: 1, Training Loss: 0.5925, Validation Loss: 0.5768\n",
      "Epoch: 2, Training Loss: 0.5416, Validation Loss: 0.5422\n",
      "Epoch: 3, Training Loss: 0.4891, Validation Loss: 0.5376\n",
      "Epoch: 4, Training Loss: 0.4842, Validation Loss: 0.5468\n",
      "Epoch: 5, Training Loss: 0.4743, Validation Loss: 0.5563\n",
      "Epoch: 6, Training Loss: 0.4683, Validation Loss: 0.4905\n",
      "Epoch: 7, Training Loss: 0.5244, Validation Loss: 0.4740\n",
      "Epoch: 8, Training Loss: 0.4976, Validation Loss: 0.4673\n",
      "Epoch: 9, Training Loss: 0.4729, Validation Loss: 0.4585\n",
      "Accuracy (deep): 0.82, Validation Acc: 0.78\n",
      "Deep: 81.55% (+/- 0.45%)\n",
      "Deep Validation: 78.13% (+/- 0.05%)\n"
     ]
    }
   ],
   "source": [
    "def model_train(model, X_train, y_train, X_val, y_val):\n",
    "    # Loss function and optimizer\n",
    "    loss_fn = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Number of epochs and batch size\n",
    "    n_epochs = 10\n",
    "    batch_size = 1000\n",
    "\n",
    "    # Initialize best accuracy and weights\n",
    "    best_acc = -np.inf\n",
    "    best_weights = None\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        with tqdm.tqdm(range(len(X_train) // batch_size), unit=\"batch\", mininterval=0, disable=True) as bar:\n",
    "            for i in bar:\n",
    "                # Get a batch of data\n",
    "                X_batch = X_train[i * batch_size:(i + 1) * batch_size]\n",
    "                y_batch = y_train[i * batch_size:(i + 1) * batch_size]\n",
    "\n",
    "                # Forward pass\n",
    "                y_pred = model(X_batch)\n",
    "\n",
    "                # Calculate the loss\n",
    "                loss = loss_fn(y_pred, y_batch)\n",
    "\n",
    "                # Backpropagate the loss\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "\n",
    "                # Update the weights\n",
    "                optimizer.step()\n",
    "\n",
    "                # Calculate the accuracy\n",
    "                acc = (y_pred.round() == y_batch).float().mean()\n",
    "\n",
    "                # Update the best accuracy and weights\n",
    "                if acc > best_acc:\n",
    "                    best_acc = acc\n",
    "                    best_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "                # Track training loss\n",
    "                train_loss = loss.item()\n",
    "\n",
    "                # Evaluate the model on the validation set\n",
    "                model.eval()\n",
    "                y_pred = model(X_val)\n",
    "                val_acc = (y_pred.round() == y_val).float().mean()\n",
    "\n",
    "                # Track validation loss\n",
    "                val_loss = loss_fn(y_pred, y_val).item()\n",
    "\n",
    "        print(\"Epoch: %d, Training Loss: %.4f, Validation Loss: %.4f\" % (epoch, train_loss, val_loss))\n",
    "\n",
    "    # Return the best accuracy and validation accuracy\n",
    "    return best_acc, val_acc\n",
    "\n",
    "\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "\n",
    "cv_scores_deep = []\n",
    "cv_val_scores_deep = []\n",
    "\n",
    "for train, test in kfold.split(X_train, y_train):\n",
    "    \n",
    "    model = DeepNet()\n",
    "    #model = Deep_wide_Net()\n",
    "    acc, val_acc = model_train(model, X_train[train], y_train[train], X_train[test], y_train[test])\n",
    "    print(\"Accuracy (deep): %.2f, Validation Acc: %.2f\" % (acc, val_acc))\n",
    "    cv_scores_deep.append(acc)\n",
    "    cv_val_scores_deep.append(val_acc)\n",
    "    \n",
    "    \n",
    "deep_acc = np.mean(cv_scores_deep)\n",
    "deep_std = np.std(cv_scores_deep)\n",
    "deep_val_acc = np.mean(cv_val_scores_deep)\n",
    "deep_val_std = np.std(cv_val_scores_deep)\n",
    "print(\"Deep: %.2f%% (+/- %.2f%%)\" % (deep_acc*100, deep_std*100))\n",
    "print(\"Deep Validation: %.2f%% (+/- %.2f%%)\" % (deep_val_acc*100, deep_val_std*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Batch [10/2743], Loss: 0.6867\n",
      "Epoch [1/10], Batch [20/2743], Loss: 0.7185\n",
      "Epoch [1/10], Batch [30/2743], Loss: 0.6457\n",
      "Epoch [1/10], Batch [40/2743], Loss: 0.5483\n",
      "Epoch [1/10], Batch [50/2743], Loss: 0.5523\n",
      "Epoch [1/10], Batch [60/2743], Loss: 0.9352\n",
      "Epoch [1/10], Batch [70/2743], Loss: 0.5671\n",
      "Epoch [1/10], Batch [80/2743], Loss: 0.4657\n",
      "Epoch [1/10], Batch [90/2743], Loss: 0.6209\n",
      "Epoch [1/10], Batch [100/2743], Loss: 0.5861\n",
      "Epoch [1/10], Batch [110/2743], Loss: 0.4733\n",
      "Epoch [1/10], Batch [120/2743], Loss: 0.6986\n",
      "Epoch [1/10], Batch [130/2743], Loss: 0.5486\n",
      "Epoch [1/10], Batch [140/2743], Loss: 0.6310\n",
      "Epoch [1/10], Batch [150/2743], Loss: 0.7371\n",
      "Epoch [1/10], Batch [160/2743], Loss: 0.5165\n",
      "Epoch [1/10], Batch [170/2743], Loss: 0.5230\n",
      "Epoch [1/10], Batch [180/2743], Loss: 0.6340\n",
      "Epoch [1/10], Batch [190/2743], Loss: 0.5800\n",
      "Epoch [1/10], Batch [200/2743], Loss: 0.6721\n",
      "Epoch [1/10], Batch [210/2743], Loss: 0.5257\n",
      "Epoch [1/10], Batch [220/2743], Loss: 0.5481\n",
      "Epoch [1/10], Batch [230/2743], Loss: 0.4617\n",
      "Epoch [1/10], Batch [240/2743], Loss: 0.5845\n",
      "Epoch [1/10], Batch [250/2743], Loss: 0.2549\n",
      "Epoch [1/10], Batch [260/2743], Loss: 0.4291\n",
      "Epoch [1/10], Batch [270/2743], Loss: 0.3988\n",
      "Epoch [1/10], Batch [280/2743], Loss: 0.2754\n",
      "Epoch [1/10], Batch [290/2743], Loss: 0.5046\n",
      "Epoch [1/10], Batch [300/2743], Loss: 0.6259\n",
      "Epoch [1/10], Batch [310/2743], Loss: 0.6268\n",
      "Epoch [1/10], Batch [320/2743], Loss: 0.4544\n",
      "Epoch [1/10], Batch [330/2743], Loss: 0.5470\n",
      "Epoch [1/10], Batch [340/2743], Loss: 0.3993\n",
      "Epoch [1/10], Batch [350/2743], Loss: 0.7915\n",
      "Epoch [1/10], Batch [360/2743], Loss: 0.7040\n",
      "Epoch [1/10], Batch [370/2743], Loss: 0.3398\n",
      "Epoch [1/10], Batch [380/2743], Loss: 0.5451\n",
      "Epoch [1/10], Batch [390/2743], Loss: 0.2447\n",
      "Epoch [1/10], Batch [400/2743], Loss: 0.4762\n",
      "Epoch [1/10], Batch [410/2743], Loss: 0.3421\n",
      "Epoch [1/10], Batch [420/2743], Loss: 0.4585\n",
      "Epoch [1/10], Batch [430/2743], Loss: 0.5681\n",
      "Epoch [1/10], Batch [440/2743], Loss: 0.4717\n",
      "Epoch [1/10], Batch [450/2743], Loss: 0.5216\n",
      "Epoch [1/10], Batch [460/2743], Loss: 0.5786\n",
      "Epoch [1/10], Batch [470/2743], Loss: 0.4705\n",
      "Epoch [1/10], Batch [480/2743], Loss: 0.4787\n",
      "Epoch [1/10], Batch [490/2743], Loss: 0.3788\n",
      "Epoch [1/10], Batch [500/2743], Loss: 0.5123\n",
      "Epoch [1/10], Batch [510/2743], Loss: 0.4190\n",
      "Epoch [1/10], Batch [520/2743], Loss: 0.7072\n",
      "Epoch [1/10], Batch [530/2743], Loss: 0.8481\n",
      "Epoch [1/10], Batch [540/2743], Loss: 0.6511\n",
      "Epoch [1/10], Batch [550/2743], Loss: 0.2707\n",
      "Epoch [1/10], Batch [560/2743], Loss: 0.6459\n",
      "Epoch [1/10], Batch [570/2743], Loss: 0.3348\n",
      "Epoch [1/10], Batch [580/2743], Loss: 0.4136\n",
      "Epoch [1/10], Batch [590/2743], Loss: 0.6647\n",
      "Epoch [1/10], Batch [600/2743], Loss: 0.6076\n",
      "Epoch [1/10], Batch [610/2743], Loss: 0.6363\n",
      "Epoch [1/10], Batch [620/2743], Loss: 0.4996\n",
      "Epoch [1/10], Batch [630/2743], Loss: 0.2418\n",
      "Epoch [1/10], Batch [640/2743], Loss: 0.4260\n",
      "Epoch [1/10], Batch [650/2743], Loss: 0.5686\n",
      "Epoch [1/10], Batch [660/2743], Loss: 0.5853\n",
      "Epoch [1/10], Batch [670/2743], Loss: 0.2369\n",
      "Epoch [1/10], Batch [680/2743], Loss: 0.3907\n",
      "Epoch [1/10], Batch [690/2743], Loss: 0.3388\n",
      "Epoch [1/10], Batch [700/2743], Loss: 0.4524\n",
      "Epoch [1/10], Batch [710/2743], Loss: 0.4214\n",
      "Epoch [1/10], Batch [720/2743], Loss: 0.6475\n",
      "Epoch [1/10], Batch [730/2743], Loss: 0.4464\n",
      "Epoch [1/10], Batch [740/2743], Loss: 0.4694\n",
      "Epoch [1/10], Batch [750/2743], Loss: 0.4401\n",
      "Epoch [1/10], Batch [760/2743], Loss: 0.3877\n",
      "Epoch [1/10], Batch [770/2743], Loss: 0.4550\n",
      "Epoch [1/10], Batch [780/2743], Loss: 0.4224\n",
      "Epoch [1/10], Batch [790/2743], Loss: 0.4772\n",
      "Epoch [1/10], Batch [800/2743], Loss: 0.3474\n",
      "Epoch [1/10], Batch [810/2743], Loss: 0.1993\n",
      "Epoch [1/10], Batch [820/2743], Loss: 0.5593\n",
      "Epoch [1/10], Batch [830/2743], Loss: 0.2568\n",
      "Epoch [1/10], Batch [840/2743], Loss: 0.3348\n",
      "Epoch [1/10], Batch [850/2743], Loss: 0.5743\n",
      "Epoch [1/10], Batch [860/2743], Loss: 0.4800\n",
      "Epoch [1/10], Batch [870/2743], Loss: 0.3252\n",
      "Epoch [1/10], Batch [880/2743], Loss: 0.5556\n",
      "Epoch [1/10], Batch [890/2743], Loss: 0.2620\n",
      "Epoch [1/10], Batch [900/2743], Loss: 0.5877\n",
      "Epoch [1/10], Batch [910/2743], Loss: 0.2189\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Update the weights\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (batch_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m], Batch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_idx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(trainloader)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m], Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\optim\\optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m--> 140\u001b[0m     out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\optim\\optimizer.py:23\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     22\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 23\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\optim\\adam.py:234\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[0;32m    231\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`requires_grad` is not supported for `step` in differentiable mode\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    232\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m--> 234\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m         \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m         \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m         \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m         \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[43m         \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m         \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m         \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[43m         \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m         \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m         \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\optim\\adam.py:300\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    298\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 300\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    308\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\optim\\adam.py:363\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    360\u001b[0m     param \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mview_as_real(param)\n\u001b[0;32m    362\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m--> 363\u001b[0m \u001b[43mexp_avg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39madd_(grad, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[0;32m    364\u001b[0m exp_avg_sq\u001b[38;5;241m.\u001b[39mmul_(beta2)\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad\u001b[38;5;241m.\u001b[39mconj(), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = DeepNet()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss for binary classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # You can adjust the learning rate\n",
    "\n",
    "# Move the model to the appropriate device (CPU or GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10  # Adjust the number of epochs as needed\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(trainloader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Validation loop\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, targets in valloader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # You can define your own accuracy calculation here\n",
    "        # For binary classification, you can use something like this:\n",
    "        predicted = outputs > 0.5\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    print(f\"Validation Accuracy: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name_of_model='WM_BM_BW_deep_wide.pth'\n",
    "\n",
    "# WM_BM_BW_train done\n",
    "# WW_BW_BM_train done\n",
    "# BM_WM_WW_train done\n",
    "# WW_WM_BW_train done\n",
    "\n",
    "# name_of_model='WW_WM_BW.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), name_of_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGEP</th>\n",
       "      <th>SCHL</th>\n",
       "      <th>MAR</th>\n",
       "      <th>RELP</th>\n",
       "      <th>DIS</th>\n",
       "      <th>ESP</th>\n",
       "      <th>CIT</th>\n",
       "      <th>MIG</th>\n",
       "      <th>MIL</th>\n",
       "      <th>ANC</th>\n",
       "      <th>NATIVITY</th>\n",
       "      <th>DEAR</th>\n",
       "      <th>DEYE</th>\n",
       "      <th>DREM</th>\n",
       "      <th>SEX</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>ESR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGEP  SCHL  MAR  RELP  DIS  ESP  CIT  MIG  MIL  ANC  NATIVITY  DEAR  DEYE  \\\n",
       "0  73.0  10.0  4.0   0.0  1.0  0.0  1.0  1.0  4.0  1.0       1.0   2.0   2.0   \n",
       "1  31.0  21.0  5.0   0.0  2.0  0.0  1.0  1.0  4.0  2.0       1.0   2.0   2.0   \n",
       "2  41.0  17.0  1.0   0.0  2.0  0.0  1.0  1.0  4.0  1.0       1.0   2.0   2.0   \n",
       "3  48.0  16.0  1.0   1.0  2.0  0.0  1.0  1.0  4.0  1.0       1.0   2.0   2.0   \n",
       "4  16.0  13.0  5.0   2.0  2.0  2.0  1.0  1.0  0.0  1.0       1.0   2.0   2.0   \n",
       "\n",
       "   DREM  SEX  RAC1P    ESR  \n",
       "0   1.0  1.0    2.0  False  \n",
       "1   2.0  2.0    1.0   True  \n",
       "2   2.0  1.0    1.0   True  \n",
       "3   2.0  2.0    1.0  False  \n",
       "4   2.0  1.0    1.0  False  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SEX  RAC1P\n",
       "1.0  1.0      16783\n",
       "     2.0       4988\n",
       "     3.0        110\n",
       "     4.0          1\n",
       "     5.0         28\n",
       "     6.0        290\n",
       "     7.0          8\n",
       "     8.0        253\n",
       "     9.0        395\n",
       "2.0  1.0      18044\n",
       "     2.0       5653\n",
       "     3.0         97\n",
       "     4.0          1\n",
       "     5.0         19\n",
       "     6.0        327\n",
       "     7.0          7\n",
       "     8.0        215\n",
       "     9.0        426\n",
       "dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_frq_test = merged_df_test.groupby(['SEX', 'RAC1P']).size()\n",
    "counts_frq_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "WM_BM_BW_test= pd.concat([WM_test,BM_test,BW_test])\n",
    "\n",
    "WW_BW_BM_test= pd.concat([WW_test,BW_test,BM_test])\n",
    "\n",
    "BM_WM_WW_test= pd.concat([WM_test,WM_test,WW_test])\n",
    "\n",
    "WW_WM_BW_test= pd.concat([WW_test,WM_test,BW_test])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "a42ccb73e7d9bfdf27e036f1d2b8b681e55fc0743cc5586bc2474d4a60f4b886"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
